# -*- coding: utf-8 -*-
"""for_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/186RzCRWCj2nK5SGZIW6SZDAfSiOceFbx

### Imports
"""

import logging
# Commented out IPython magic to ensure Python compatibility.
from pycocotools.coco import COCO
import numpy as np
import skimage.io as io
import random
import os
import cv2
import sys
### For visualizing the outputs ###
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from torchvision.transforms import ToTensor, ToPILImage
# %matplotlib inline

from collections import defaultdict, deque
import datetime
import pickle
import time
import torch.distributed as dist
import errno

import collections
import os
import numpy as np
import torch
import torch.utils.data
from PIL import Image, ImageFile
import pandas as pd
from tqdm import tqdm
from torchvision import transforms
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from torchvision.ops import boxes as bx
ImageFile.LOAD_TRUNCATED_IMAGES = True
CUDA_LAUNCH_BLOCKING = 1
sys.path.append("./TorchvisionObjectDetection")
from engine import train_one_epoch, evaluate
import utils



"""### Prepare DataSet"""

def getClassName(classID, cats):
    for i in range(len(cats)):
        if cats[i]['id']==classID:
            return cats[i]['name']
    return "None"

class DocLayNetDataset(torch.utils.data.Dataset):
      def __init__(self, imgDir, annotFile, maxImgs=None):
        self.height = 256
        self.width = 256
        self.imgDir = imgDir
        self.annotations = COCO(annotFile)
        if maxImgs != None:
        	self.imgIDs = self.annotations.getImgIds()[0:maxImgs]
        else:
        	self.imgIDs = self.annotations.getImgIds()
        self.catIDs = self.annotations.getCatIds()
        self.cats = self.annotations.loadCats(self.catIDs)
        #self.imgIDs.remove(456) #456 is the id of an empty document which gaves empty boxes
        #self.imgIDs.remove(987)
        #self.imgIDs.remove(24)
        goodIds = []
        for idx in self.imgIDs:
            annIds = self.annotations.getAnnIds(idx, self.catIDs, iscrowd=None)
            anns = self.annotations.loadAnns(annIds)
            boxes = [ann['bbox'] for ann in anns]
            if len(boxes)!=0:
                    goodIds.append(idx)
        self.imgIDs = goodIds
      def __getitem__(self, index):
        id = self.imgIDs[index]
        #print("id", id)
        img = self.annotations.loadImgs(id)[0]
        #print(img)
        #I = io.imread(imgDir+'/'+img['file_name'])/255.0
        I = Image.open(self.imgDir+'/'+img['file_name']).convert("RGB")
        #print(type(I))
        I = I.resize((self.width, self.height), resample=Image.BILINEAR)
        
        I = np.array(I.getdata()).reshape(I.size[0], I.size[1], 3)
        #print(I.shape)
      
        annIds = self.annotations.getAnnIds(id, self.catIDs, iscrowd=None)
        #print("self.cats", self.cats)
        #print("annIds",annIds)
        #print("self.annotations",self.annotations)
        anns = self.annotations.loadAnns(annIds)
        #print("anns", anns)
        boxes = [ann['bbox'] for ann in anns]
        if len(boxes)==0:
            print("Empty Box Warning: ", img['file_name'], ", ID: ", id)
        labels = [ann['category_id'] for ann in anns]
        areas = [ann['area']*((self.width/img["width"])*(self.height/img["height"])) for ann in anns]
        iscrowds = [ann['iscrowd'] for ann in anns]
        classes = [cat['name'] for cat in self.cats]
        #binary mask [N,H,W] N number of instances
        normal_mask = np.zeros((img['height'],img['width']))
        for i in range(len(anns)):
          className = getClassName(anns[i]['category_id'], self.cats)
          pixel_value = classes.index(className)+1
          normal_mask = np.maximum(self.annotations.annToMask(anns[i])*pixel_value, normal_mask)
        #print("normal mask", normal_mask.shape)
        
        bin_msk = Image.fromarray(normal_mask)
        bin_msk = bin_msk.resize((self.width, self.height), resample=Image.BILINEAR)
        normal_mask = np.array(bin_msk.getdata()).reshape(bin_msk.size[0], bin_msk.size[1])
        #print("normal", normal_mask.shape)
        #print("normal", np.max(normal_mask))

        binary_mask = np.zeros((len(anns),self.height,self.width))
        for instance in range(len(anns)):
          bin_msk = Image.fromarray(self.annotations.annToMask(anns[instance]))
          bin_msk = bin_msk.resize((self.width, self.height), resample=Image.BILINEAR)
          bin_msk = np.array(bin_msk.getdata()).reshape(bin_msk.size[0], bin_msk.size[1])
          binary_mask[instance,:,:] = bin_msk[:,:]

          """
          for i in range(self.height):
            for j in range(self.width):
              binary_mask[instance,i,j] = (self.annotations.annToMask(anns[instance])[i,j])
          """
        #print("binary mask", binary_mask.shape)
        
        boxes_np = np.asarray(boxes)*(self.width/img["width"])
        boxes_tr = torch.as_tensor(boxes_np, dtype=torch.float32)
        #print("boxes_tr", boxes)
        labels_tr = torch.as_tensor(labels, dtype=torch.int64)
        #print("labels_tr", labels_tr)
        masks_tr = torch.as_tensor(binary_mask, dtype=torch.uint8)
        #print("masks_tr", masks_tr)
        areas_tr = torch.as_tensor(areas, dtype=torch.float32)
        iscrowds_tr = torch.as_tensor(iscrowds, dtype=torch.uint8)
        target = {}
        target['boxes'] = bx.box_convert(boxes_tr, 'xywh', 'xyxy')
        target['labels']= labels_tr
        target['masks'] = masks_tr
        target['image_id'] = torch.as_tensor(id, dtype=torch.int64)
        target['area'] = areas_tr
        target['iscrowd'] = iscrowds_tr
        

        I = np.transpose(I, [2,0,1])/np.max(I)
        img = torch.tensor(I).float()
        img = img.cuda()
        return img, target


      def __len__(self):
        return len(self.imgIDs)

TraindataSet = DocLayNetDataset('PNG', 'COCO/train.json', maxImgs=2000)

"""### Data Loader"""

data_loader_train = torch.utils.data.DataLoader(TraindataSet, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))

"""### MODEL"""

num_classes=12
# load an instance segmentation model pre-trained pre-trained on COCO
model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained = True)

    # get number of input features for the classifier
in_features = model.roi_heads.box_predictor.cls_score.in_features
    # replace the pre-trained head with a new one
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    # now get the number of input features for the mask classifier
in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
hidden_layer = 256
    # and replace the mask predictor with a new one
model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,
                                                       hidden_layer,
                                                       num_classes)

"""### Training"""

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
#device = torch.device('cpu')
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.0025,
                                momentum=0.9, weight_decay=0.0001)
    # and a learning rate scheduler
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,
                                                   step_size=3,
                                                   gamma=0.1)

# let's train it for n epochs
num_epochs = 5

model.cuda()
#model.cpu()

torch.backends.cudnn.enabled = True

for epoch in range(num_epochs):
        try:
        # train for one epoch, printing every 10 iterations
        	train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)
        # update the learning rate
        	lr_scheduler.step()
        except Exception as e:
        	logging.error(e, exc_info=True)

torch.save(model, "trained_mask-rcnn-{}_epochs".format(num_epochs))
